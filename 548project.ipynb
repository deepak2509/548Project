{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa162000-8ae8-4090-9f0d-88d03b97bf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm doing well, thank you. How are you this fine evening? Do you have any plans?\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "# Load the tokenizer and model\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Example conversation\n",
    "inputs = tokenizer(\"Hi, how are you?\", return_tensors=\"pt\")\n",
    "reply_ids = model.generate(inputs[\"input_ids\"])\n",
    "print(tokenizer.decode(reply_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f69f011-9979-49ef-82e2-e0810eedcf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chicken Alfredo. It's my favorite. What do you like to cook?\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"What should i cook for dinner\", return_tensors=\"pt\")\n",
    "reply_ids = model.generate(inputs[\"input_ids\"])\n",
    "print(tokenizer.decode(reply_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c0a6c2-4e2c-4aaf-b0d6-9b49a79505f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot:  Chicken Alfredo. It's one of my favorites. What do you like to cook?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  No, I would like to cook pasta instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot:  Pasta is always a good choice. What kind of pasta do you want to make?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I want to cook red sauce pasta.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot:  I love pasta! I like to make spaghetti and meatballs.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  okay, great!. give me the recipe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatBot:  Pasta is one of the most popular foods in the world. I'm sure you can find a good recipe online.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending the conversation. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Initialize conversation history\n",
    "conversation_history = \"What should I cook for dinner?\"\n",
    "\n",
    "# Tokenize the input and generate a reply\n",
    "inputs = tokenizer(conversation_history, return_tensors=\"pt\")\n",
    "reply_ids = model.generate(inputs[\"input_ids\"])\n",
    "reply = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "print(f\"ChatBot: {reply}\")\n",
    "\n",
    "# Update conversation history\n",
    "while True:\n",
    "    user_input = input(\"You: \")  # Take user input\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Ending the conversation. Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Append user input to the conversation history\n",
    "    conversation_history += f\" {user_input}\"\n",
    "\n",
    "    # Tokenize updated conversation and generate a new reply\n",
    "    inputs = tokenizer(conversation_history, return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(inputs[\"input_ids\"])\n",
    "    reply = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "    print(f\"ChatBot: {reply}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e6240-ec13-488f-be47-07fd44f1a4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
